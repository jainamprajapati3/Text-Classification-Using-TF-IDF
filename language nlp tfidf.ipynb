{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c6e82c",
   "metadata": {},
   "source": [
    "# Text Classification using Bag word, TF-IDF, Word2Vec using NLP \n",
    "\n",
    "ROll No-\n",
    "\n",
    "20BIC030-Kushal Patel\n",
    "\n",
    "20BIC034-Jainam Prajapti\n",
    "\n",
    "20BIC034-Pranjal Mairal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80476eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a7355e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  language\n",
      "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
      "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
      "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
      "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
      "4  de spons behoort tot het geslacht haliclona en...     Dutch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\Jainam D Prajapati\\Downloads\\dataset.csv\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acceb912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52d4f82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "language    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5e3e5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Estonian      1000\n",
       "Swedish       1000\n",
       "English       1000\n",
       "Russian       1000\n",
       "Romanian      1000\n",
       "Persian       1000\n",
       "Pushto        1000\n",
       "Spanish       1000\n",
       "Hindi         1000\n",
       "Korean        1000\n",
       "Chinese       1000\n",
       "French        1000\n",
       "Portugese     1000\n",
       "Indonesian    1000\n",
       "Urdu          1000\n",
       "Latin         1000\n",
       "Turkish       1000\n",
       "Japanese      1000\n",
       "Dutch         1000\n",
       "Tamil         1000\n",
       "Thai          1000\n",
       "Arabic        1000\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['language'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c7c3c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Text  language\n",
      "0      klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
      "1      sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
      "2      ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
      "3      விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
      "4      de spons behoort tot het geslacht haliclona en...     Dutch\n",
      "...                                                  ...       ...\n",
      "21995  hors du terrain les années  et  sont des année...    French\n",
      "21996  ใน พศ  หลักจากที่เสด็จประพาสแหลมมลายู ชวา อินเ...      Thai\n",
      "21997  con motivo de la celebración del septuagésimoq...   Spanish\n",
      "21998  年月，當時還只有歲的她在美國出道，以mai-k名義推出首張英文《baby i like》，由...   Chinese\n",
      "21999   aprilie sonda spațială messenger a nasa și-a ...  Romanian\n",
      "\n",
      "[22000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates()          \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b766747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 57772)\t1\n",
      "  (0, 43363)\t1\n",
      "  (0, 104967)\t3\n",
      "  (0, 80287)\t1\n",
      "  (0, 75304)\t2\n",
      "  (0, 80056)\t1\n",
      "  (0, 67653)\t1\n",
      "  (0, 77619)\t1\n",
      "  (0, 2193)\t1\n",
      "  (0, 63122)\t1\n",
      "  (0, 47020)\t1\n",
      "  (0, 53103)\t2\n",
      "  (0, 79323)\t1\n",
      "  (0, 80288)\t1\n",
      "  (0, 45293)\t1\n",
      "  (0, 49445)\t1\n",
      "  (0, 60954)\t1\n",
      "  (0, 112024)\t1\n",
      "  (0, 136)\t1\n",
      "  (0, 117124)\t1\n",
      "  (0, 106285)\t1\n",
      "  (0, 67654)\t1\n",
      "  (0, 122429)\t1\n",
      "  (0, 59244)\t1\n",
      "  (0, 122097)\t1\n",
      "  :\t:\n",
      "  (21999, 123303)\t1\n",
      "  (21999, 17371)\t2\n",
      "  (21999, 4888)\t1\n",
      "  (21999, 74014)\t1\n",
      "  (21999, 66036)\t1\n",
      "  (21999, 81608)\t1\n",
      "  (21999, 123334)\t1\n",
      "  (21999, 38077)\t1\n",
      "  (21999, 6023)\t1\n",
      "  (21999, 104844)\t1\n",
      "  (21999, 40786)\t1\n",
      "  (21999, 6037)\t1\n",
      "  (21999, 103845)\t1\n",
      "  (21999, 84356)\t1\n",
      "  (21999, 70726)\t1\n",
      "  (21999, 101742)\t2\n",
      "  (21999, 69551)\t1\n",
      "  (21999, 95539)\t1\n",
      "  (21999, 69301)\t2\n",
      "  (21999, 101537)\t1\n",
      "  (21999, 102254)\t1\n",
      "  (21999, 88346)\t1\n",
      "  (21999, 20053)\t1\n",
      "  (21999, 123275)\t1\n",
      "  (21999, 43690)\t1\n"
     ]
    }
   ],
   "source": [
    "x = np.array(data['Text'])#To assign the value of the text column in a variable name x.\n",
    "y = np.array(data['language'])#To assign the value of the text column in a variable name y \n",
    "#The fit data will calculated the mean and standard deviation among the data,and the transform will perfom scaling using the mean and standard deviation calculating using the data.\n",
    "\n",
    "cv = CountVectorizer()\n",
    "x1 = cv.fit_transform(x)\n",
    "print(x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00de671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 122429)\t0.11632821567894927\n",
      "  (0, 122098)\t0.15245962403688545\n",
      "  (0, 122097)\t0.15245962403688545\n",
      "  (0, 117124)\t0.13392659423607992\n",
      "  (0, 113245)\t0.1389042716940385\n",
      "  (0, 112024)\t0.15245962403688545\n",
      "  (0, 106285)\t0.08285492222494331\n",
      "  (0, 104967)\t0.42661618752454356\n",
      "  (0, 80288)\t0.15245962403688545\n",
      "  (0, 80287)\t0.15245962403688545\n",
      "  (0, 80056)\t0.1464612850687559\n",
      "  (0, 79323)\t0.15245962403688545\n",
      "  (0, 77619)\t0.08182087878336176\n",
      "  (0, 76696)\t0.1389042716940385\n",
      "  (0, 75304)\t0.16625026948941637\n",
      "  (0, 75247)\t0.2290289414877052\n",
      "  (0, 67654)\t0.15245962403688545\n",
      "  (0, 67653)\t0.15245962403688545\n",
      "  (0, 63450)\t0.2433938789015453\n",
      "  (0, 63122)\t0.13392659423607992\n",
      "  (0, 60954)\t0.1464612850687559\n",
      "  (0, 59244)\t0.15245962403688545\n",
      "  (0, 57772)\t0.1389042716940385\n",
      "  (0, 55264)\t0.26785318847215983\n",
      "  (0, 53103)\t0.1322820868685367\n",
      "  :\t:\n",
      "  (21999, 104844)\t0.16248852574304734\n",
      "  (21999, 103845)\t0.18186228813180896\n",
      "  (21999, 102254)\t0.18987120980426156\n",
      "  (21999, 101742)\t0.3576348748525535\n",
      "  (21999, 101537)\t0.19555363016241606\n",
      "  (21999, 97734)\t0.07526526548636828\n",
      "  (21999, 95539)\t0.18546358214789696\n",
      "  (21999, 88346)\t0.20356255183486865\n",
      "  (21999, 84356)\t0.17385336645935637\n",
      "  (21999, 81608)\t0.10343937006427364\n",
      "  (21999, 74014)\t0.13510584168183312\n",
      "  (21999, 70726)\t0.18987120980426156\n",
      "  (21999, 69551)\t0.18987120980426156\n",
      "  (21999, 69301)\t0.3911072603248321\n",
      "  (21999, 66036)\t0.10270771489197011\n",
      "  (21999, 43690)\t0.20356255183486865\n",
      "  (21999, 40786)\t0.15215310275629662\n",
      "  (21999, 38077)\t0.1309466755562267\n",
      "  (21999, 28194)\t0.09160270401248888\n",
      "  (21999, 25042)\t0.19212934088982778\n",
      "  (21999, 20053)\t0.20356255183486865\n",
      "  (21999, 17371)\t0.20944489288925866\n",
      "  (21999, 6037)\t0.16016202442874922\n",
      "  (21999, 6023)\t0.14759970003791315\n",
      "  (21999, 4888)\t0.1290413507799354\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfTransformer().fit(x1) #To find the term frequency(term count) vectord for different sentences(task).\n",
    "x = tfidf.transform(x1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74c4e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It will split the data into the test and train variable according to the size of the variable given to it \n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe26381a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Linear Kernel: 0.9478787878787879\n",
      "Accuracy Polynomial Kernel: 0.6239393939393939\n",
      "Accuracy Radial Basis Kernel: 0.9283333333333333\n",
      "Accuracy Sigmoid Kernel: 0.943939393939394\n"
     ]
    }
   ],
   "source": [
    "#In SVC we define the classifier by using the LinearSVC class. We can use the default parameters of the class. The parameters can be changed according to classification data content.\n",
    "#In this Model we have classify the data by giving differnet type of shape to the kernel like as Linear,rbf,polynomial and sigmoid \n",
    "#The decision_function_shape is a function values are proportional to the distance of the samples X to the separating hyperplane.\n",
    "#'C' it Shows the penalty of the error term.\n",
    "#By using all the condition we will fit the data into the model\n",
    "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(x_train, y_train)\n",
    "rbf = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(x_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(x_train, y_train)\n",
    "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(x_train, y_train)\n",
    "\n",
    "#To predict the values by usind different classification methods.\n",
    "\n",
    "linear_pred = linear.predict(x_test)\n",
    "poly_pred = poly.predict(x_test)\n",
    "rbf_pred = rbf.predict(x_test)\n",
    "sig_pred = sig.predict(x_test)\n",
    "\n",
    "#To check the accuracy of the svm\n",
    "accuracy_lin = linear.score(x_test, y_test)\n",
    "accuracy_poly = poly.score(x_test, y_test)\n",
    "accuracy_rbf = rbf.score(x_test, y_test)\n",
    "accuracy_sig = sig.score(x_test, y_test)\n",
    "\n",
    "print(\"Accuracy Linear Kernel:\", accuracy_lin)\n",
    "print(\"Accuracy Polynomial Kernel:\", accuracy_poly)\n",
    "print(\"Accuracy Radial Basis Kernel:\", accuracy_rbf)\n",
    "print(\"Accuracy Sigmoid Kernel:\", accuracy_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a1fcffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of traning 0.9999350649350649\n",
      "cv average score  [0.97077922 0.96980519 0.96201299 0.96266234 0.96688312]\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC() #To call the LinearSVC Algorithm\n",
    "lsvc.fit(x_train, y_train) #IT will fit the traning data and the testing data into the algorithm\n",
    "score = lsvc.score(x_train, y_train)\n",
    "print(\"score of traning\",score)\n",
    "\n",
    "cv_scores = cross_val_score(lsvc, x_train,y_train) #IT is used to check the traning score of the data given to the lsvc(linear support vecot machine) \n",
    "print(\"cv average score \",cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d7520b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Japanese' 'Russian' 'Latin' ... 'Spanish' 'Arabic' 'Estonian']\n"
     ]
    }
   ],
   "source": [
    "y_pred = lsvc.predict(x_test)#It will give the predicted value by taking the value as an input from x_test\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a4efef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[299   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0 282   0   5   0   0   0   0   4   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0 312   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   1   0 286   0   0   0   0   0   0   1   0   0   0   0   0   1   0\n",
      "    0   0   0   0]\n",
      " [  0   3   0   0 299   1   0   1   0   0   1   0   1   0   0   2   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   3   0 283   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   1   0   2   0   0 310   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   1   0   0   0 292   1   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0 105   1   2   0   1   0   0 193   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   8   0   0   0   0   0   0   0 286   1   0   0   0   0   1   0   0\n",
      "    0   0   0   0]\n",
      " [  0   2   0   9   1   4   0   0   1   0 295   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   1   0   1   0   0   0   0   0   0   0 297   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   2   0 290   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   3   0   5   0   0   0   0   0   0   0   0   0 294   0   1   0   0\n",
      "    0   0   0   0]\n",
      " [  0   1   0   3   0   1   0   0   0   0   1   0   0   0 285   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   1   0   1   0   0   0   0   0   0   0   0   0   0   0 300   0   0\n",
      "    0   0   0   0]\n",
      " [  0   1   0   1   0   0   0   0   1   0   1   0   0   0   0   0 283   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 290\n",
      "    0   0   0   0]\n",
      " [  0   1   0   2   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "  297   0   0   0]\n",
      " [  0   1   0   5   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 298   0   0]\n",
      " [  0   1   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0 295   0]\n",
      " [  0   1   0   4   0   0   0   0   0   0   0   1   0   0   0   0   1   0\n",
      "    0   0   0 317]]\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      1.00      1.00       300\n",
      "     Chinese       0.68      0.97      0.80       291\n",
      "       Dutch       1.00      1.00      1.00       313\n",
      "     English       0.86      0.99      0.92       289\n",
      "    Estonian       1.00      0.97      0.98       308\n",
      "      French       0.97      0.99      0.98       287\n",
      "       Hindi       1.00      0.99      0.99       314\n",
      "  Indonesian       1.00      0.99      0.99       295\n",
      "    Japanese       0.96      0.64      0.77       302\n",
      "      Korean       1.00      0.97      0.98       296\n",
      "       Latin       0.97      0.95      0.96       312\n",
      "     Persian       1.00      0.99      0.99       299\n",
      "   Portugese       0.99      0.99      0.99       293\n",
      "      Pushto       1.00      0.97      0.98       303\n",
      "    Romanian       1.00      0.98      0.99       291\n",
      "     Russian       0.99      0.99      0.99       302\n",
      "     Spanish       0.99      0.99      0.99       287\n",
      "     Swedish       1.00      1.00      1.00       290\n",
      "       Tamil       1.00      0.99      0.99       301\n",
      "        Thai       1.00      0.98      0.99       305\n",
      "     Turkish       1.00      0.99      0.99       298\n",
      "        Urdu       1.00      0.98      0.99       324\n",
      "\n",
      "    accuracy                           0.97      6600\n",
      "   macro avg       0.97      0.97      0.97      6600\n",
      "weighted avg       0.97      0.97      0.97      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#By predicting the value from the test data and to check the accuracy of the predicted value we use the confussion matrix for SVM Method \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"confusion matrix:\",cm)\n",
    "\n",
    "\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(\"Classification report: \",cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6419a8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9671212121212122\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred)) #TO print the accuracy between the predicted value and and the test value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c80f883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your text: Students are allowed to carry kirpans on campus as long \n",
      "['English']\n"
     ]
    }
   ],
   "source": [
    "testing = input(\"Enter your text: \")\n",
    "dt1 = cv.transform([testing]).toarray()\n",
    "output = lsvc.predict(dt1)\n",
    "print(output)\n",
    "\n",
    "#Output by using the Linear SVC(Support Vector Machine) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "120e70cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv average score  [0.95681818 0.95649351 0.95097403 0.9512987  0.95519481]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#APPLYING MULTINOMIALNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "cv_scores = cross_val_score(model, x_train,y_train) #IT is used to check the traning score of the data given to the lsvc(linear support vecot machine) \n",
    "print(\"cv average score \",cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83086a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Japanese' 'Russian' 'Latin' ... 'Spanish' 'Arabic' 'Estonian']\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49a45cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9571212121212122\n"
     ]
    }
   ],
   "source": [
    "ac = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy is :\",ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db50e312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[299   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0 248   0  29   0   5   0   1   2   0   0   0   0   0   2   0   3   0\n",
      "    0   0   1   0]\n",
      " [  0   0 307   2   0   3   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0 288   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   1   7 296   1   0   1   0   0   0   0   0   0   0   2   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   3   0 283   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   6   0   0 308   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   7   0   0   0 288   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0  82   1  12   2   5   1   1 186   0   1   0   0   0   1   1   5   2\n",
      "    0   1   1   0]\n",
      " [  0   3   0   1   0   0   0   0   0 291   0   0   0   0   0   1   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   1  20   0   5   0   1   0   0 283   0   0   0   1   0   1   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0 298   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   9   0   0   0   0   0   0   2   0 282   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   8   0   0   0   0   0   0   0   0   0 294   0   1   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   4   0   1   0   0   0   0   0   0   0   0 286   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   3   0   0   0   0   0   0   0   0   0   0   0 299   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0 285   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 290\n",
      "    0   0   0   0]\n",
      " [  0   0   0   3   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  297   0   0   0]\n",
      " [  0   0   0   5   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 299   0   0]\n",
      " [  0   0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 293   0]\n",
      " [  0   0   0   5   0   0   0   0   0   0   0   1   0   0   0   0   1   0\n",
      "    0   0   0 317]]\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      1.00      1.00       300\n",
      "     Chinese       0.74      0.85      0.79       291\n",
      "       Dutch       0.99      0.98      0.99       313\n",
      "     English       0.68      1.00      0.81       289\n",
      "    Estonian       0.99      0.96      0.98       308\n",
      "      French       0.93      0.99      0.96       287\n",
      "       Hindi       1.00      0.98      0.99       314\n",
      "  Indonesian       0.99      0.98      0.98       295\n",
      "    Japanese       0.99      0.62      0.76       302\n",
      "      Korean       1.00      0.98      0.99       296\n",
      "       Latin       0.99      0.91      0.94       312\n",
      "     Persian       1.00      1.00      1.00       299\n",
      "   Portugese       1.00      0.96      0.98       293\n",
      "      Pushto       1.00      0.97      0.98       303\n",
      "    Romanian       0.98      0.98      0.98       291\n",
      "     Russian       0.98      0.99      0.99       302\n",
      "     Spanish       0.96      0.99      0.98       287\n",
      "     Swedish       0.99      1.00      1.00       290\n",
      "       Tamil       1.00      0.99      0.99       301\n",
      "        Thai       1.00      0.98      0.99       305\n",
      "     Turkish       0.99      0.98      0.99       298\n",
      "        Urdu       1.00      0.98      0.99       324\n",
      "\n",
      "    accuracy                           0.96      6600\n",
      "   macro avg       0.96      0.96      0.96      6600\n",
      "weighted avg       0.97      0.96      0.96      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#By predicting the value from the test data and to check the accuracy of the predicted value we use the confussion matrix for the Navyes Bays Method \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"confusion matrix:\",cm)\n",
    "\n",
    "\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(\"Classification report: \",cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5928e451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your text: चीफ सेलेक्टर कौन? अगरकर के बाद ये तीन पूर्व क्रिकेटर भी रेस में शामिल\n",
      "['Hindi']\n"
     ]
    }
   ],
   "source": [
    "#Testing of the data can be done by Multinomial Navy's Bayes Therom.\n",
    "testing = input(\"Enter your text: \")\n",
    "dt1 = cv.transform([testing]).toarray()\n",
    "output = model.predict(dt1)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90560bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To empty list generated to store the value of accuracy and the second variable is to check whether the iteration are working properly or not\n",
    "acc=[]\n",
    "y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7af76148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainam D Prajapati\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jainam D Prajapati\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jainam D Prajapati\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jainam D Prajapati\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jainam D Prajapati\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jainam D Prajapati\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jainam D Prajapati\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jainam D Prajapati\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jainam D Prajapati\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Jainam D Prajapati\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1662121212121212, 0.9225757575757576, 0.938030303030303, 0.9374242424242424, 0.9336363636363636, 0.9318181818181818, 0.9301515151515152, 0.9295454545454546, 0.9303030303030303, 0.9292424242424242, 0.9292424242424242, 0.9225757575757576, 0.9224242424242424, 0.9216666666666666, 0.9218181818181819, 0.923030303030303, 0.9231818181818182, 0.923030303030303, 0.923939393939394, 0.9254545454545454, 0.9287878787878788, 0.9268181818181818, 0.9253030303030303, 0.9246969696969697, 0.1662121212121212, 0.9225757575757576, 0.938030303030303, 0.9374242424242424, 0.9336363636363636, 0.9318181818181818, 0.9301515151515152, 0.9295454545454546, 0.9303030303030303, 0.9292424242424242, 0.9292424242424242, 0.1662121212121212, 0.9225757575757576, 0.938030303030303, 0.9374242424242424, 0.9336363636363636, 0.9318181818181818, 0.9301515151515152, 0.9295454545454546, 0.9303030303030303, 0.9292424242424242, 0.9292424242424242, 0.1662121212121212, 0.9225757575757576, 0.938030303030303, 0.9374242424242424, 0.9336363636363636, 0.9318181818181818, 0.9301515151515152, 0.9295454545454546, 0.9303030303030303, 0.9292424242424242, 0.9292424242424242, 0.1662121212121212, 0.9225757575757576, 0.938030303030303, 0.9374242424242424, 0.9336363636363636, 0.9318181818181818, 0.9301515151515152, 0.9295454545454546, 0.9303030303030303, 0.9292424242424242, 0.9292424242424242]\n",
      "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainam D Prajapati\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "#KNN Algorithm\n",
    "for i in range(1,22,2):\n",
    "  clf=KNeighborsClassifier(n_neighbors=i)\n",
    "  clf.fit(x_train,y_train)\n",
    "  y_pred=clf.predict(x_test)\n",
    "  acc.append(metrics.accuracy_score(y_test,y_pred,normalize=True))\n",
    "  y.append(i)\n",
    "print(acc)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9754a37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(acc)#Value of Maximum Accuracy\n",
    "acc.index(0.938030303030303)#At k=5 we have obtained the maximum accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10761dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[298   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   1]\n",
      " [  0 155   1  22   1   2   0   2   1   0   0   0   0 103   1   0   2   0\n",
      "    0   0   1   0]\n",
      " [  0   0 308   1   0   3   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0 288   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   1   0  10 292   1   0   1   0   0   0   0   1   0   0   2   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   3   0 283   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   6   0   0 308   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0  12   0   0   0 282   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0  37   1  10   3   3   1   1 119   1   1   0   0 118   1   1   3   2\n",
      "    0   0   0   0]\n",
      " [  0   1   0   1   0   0   0   0   0 288   0   0   0   6   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   3  20   0   6   0   1   0   0 279   0   1   0   1   0   1   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0 298   0   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   3   2   0   0   0   0   0   0   1   0 287   0   0   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   8   0   0   0   0   0   0   0   0   0 294   0   1   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   2   4   0   1   0   1   0   0   0   0   0   0 283   0   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   3   0   0   0   0   0   0   0   0   0   0   0 299   0   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0 283   0\n",
      "    0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 290\n",
      "    0   0   0   0]\n",
      " [  0   0   0   3   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  297   0   0   0]\n",
      " [  0   0   0   6   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 298   0   0]\n",
      " [  0   0   0   7   0   0   0   2   0   0   0   0   0   0   0   0   1   0\n",
      "    0   0 288   0]\n",
      " [  1   0   0   5   0   0   0   0   0   0   0   1   0   0   0   0   1   0\n",
      "    0   0   0 316]]\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "      Arabic       1.00      0.99      0.99       300\n",
      "     Chinese       0.80      0.53      0.64       291\n",
      "       Dutch       0.97      0.98      0.98       313\n",
      "     English       0.69      1.00      0.82       289\n",
      "    Estonian       0.99      0.95      0.97       308\n",
      "      French       0.94      0.99      0.96       287\n",
      "       Hindi       1.00      0.98      0.99       314\n",
      "  Indonesian       0.97      0.96      0.96       295\n",
      "    Japanese       0.99      0.39      0.56       302\n",
      "      Korean       1.00      0.97      0.98       296\n",
      "       Latin       0.99      0.89      0.94       312\n",
      "     Persian       1.00      1.00      1.00       299\n",
      "   Portugese       0.99      0.98      0.98       293\n",
      "      Pushto       0.56      0.97      0.71       303\n",
      "    Romanian       0.99      0.97      0.98       291\n",
      "     Russian       0.99      0.99      0.99       302\n",
      "     Spanish       0.97      0.99      0.98       287\n",
      "     Swedish       0.99      1.00      1.00       290\n",
      "       Tamil       1.00      0.99      0.99       301\n",
      "        Thai       1.00      0.98      0.99       305\n",
      "     Turkish       1.00      0.97      0.98       298\n",
      "        Urdu       1.00      0.98      0.99       324\n",
      "\n",
      "    accuracy                           0.93      6600\n",
      "   macro avg       0.95      0.93      0.93      6600\n",
      "weighted avg       0.95      0.93      0.93      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#By predicting the value from the test data and to check the accuracy of the predicted value we use the confussion matrix for KNN Method \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"confusion matrix:\",cm)\n",
    "\n",
    "\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(\"Classification report: \",cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "437fbc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your text: DUTCH BANKS CALL FOR MORE RESEARCH ON DIGITAL\n",
      "['English']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainam D Prajapati\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "#Testing of the data can be done by KNN.\n",
    "testing = input(\"Enter your text: \")\n",
    "dt1 = cv.transform([testing]).toarray()\n",
    "output = clf.predict(dt1)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
